{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d28c672e-2adf-48d4-a932-9eead3615484",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59fd6cd1-d07f-4142-9fb5-ad8b39e4d6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1/255,zoom_range=0.2,horizontal_flip=True,vertical_flip=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc19c064-6041-4987-8eb1-7983438e6595",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abb15498-7081-4159-8bc2-9446325480b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15750 images belonging to 9 classes.\n"
     ]
    }
   ],
   "source": [
    "x_train=train_datagen.flow_from_directory(r'C:\\Users\\LEGION\\Desktop\\Project Externship\\Dataset\\training_set',target_size=(64,64),\n",
    "                                          class_mode='categorical',batch_size=900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95d51502-6c7f-481f-93d1-fbbf8d4b8312",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c7bd1a5-f00c-4e38-8b2b-7d72b87c8342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2250 images belonging to 9 classes.\n"
     ]
    }
   ],
   "source": [
    "x_test=test_datagen.flow_from_directory(r'C:\\Users\\LEGION\\Desktop\\Project Externship\\Dataset\\test_set',target_size=(64,64),\n",
    "                                          class_mode='categorical',batch_size=900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2adc537b-4339-42fd-803d-69ba5b19205e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a91cfd6-0756-4ea5-b218-7d1b392a086f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587735d2-c2e1-41d9-9977-c2cc95d292d1",
   "metadata": {},
   "source": [
    "Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce455129-151f-4d93-b620-f9db2406426a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Convolution2D,MaxPooling2D,Flatten,Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3205e40-fa71-4ae0-819b-8a7340d7bcba",
   "metadata": {},
   "source": [
    "Creating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c153d655-bf2a-4736-86b6-ec89a4e165c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76648a39-4f81-4583-a0ec-79941c0302df",
   "metadata": {},
   "source": [
    "Adding Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e37f026-48f0-4ce0-93c5-03c15d18c86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Convolution2D(32,(3,3),activation='relu',input_shape=(64,64,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "960fcf34-1a9c-4df3-b6b9-080d31d44acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99e5e0a6-ec75-4404-a635-718e28f43826",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "025236fb-182a-408d-a38d-d6c55449de83",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Hidden Layer 1\n",
    "model.add(Dense(300,activation='relu'))\n",
    "##Hidden Layer 2\n",
    "model.add(Dense(150,activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c25c9cd-67f0-457b-ab20-172ff27d5791",
   "metadata": {},
   "source": [
    "Output Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3b8b6c28-0ee0-481d-992f-0e2c2fc29276",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(9,activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b505eb-4640-4ba1-93bc-83320621213c",
   "metadata": {},
   "source": [
    "Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "29f8b091-69b3-4fea-b6d4-6ea92c4fb717",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0381dc38-c74f-442c-a634-55899c647674",
   "metadata": {},
   "source": [
    "Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b534c848-a41a-4332-af56-332b8ae63065",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEGION\\AppData\\Local\\Temp/ipykernel_24492/234118701.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(x_train,steps_per_epoch=len(x_train),epochs=10,validation_data=x_test,validation_steps=len(x_test))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "18/18 [==============================] - 50s 3s/step - loss: 1.3134 - accuracy: 0.5780 - val_loss: 0.4696 - val_accuracy: 0.8787\n",
      "Epoch 2/10\n",
      "18/18 [==============================] - 49s 3s/step - loss: 0.3442 - accuracy: 0.9060 - val_loss: 0.3401 - val_accuracy: 0.9191\n",
      "Epoch 3/10\n",
      "18/18 [==============================] - 50s 3s/step - loss: 0.1466 - accuracy: 0.9592 - val_loss: 0.2585 - val_accuracy: 0.9418\n",
      "Epoch 4/10\n",
      "18/18 [==============================] - 50s 3s/step - loss: 0.0797 - accuracy: 0.9782 - val_loss: 0.2345 - val_accuracy: 0.9502\n",
      "Epoch 5/10\n",
      "18/18 [==============================] - 49s 3s/step - loss: 0.0494 - accuracy: 0.9865 - val_loss: 0.2327 - val_accuracy: 0.9631\n",
      "Epoch 6/10\n",
      "18/18 [==============================] - 48s 3s/step - loss: 0.0317 - accuracy: 0.9929 - val_loss: 0.2524 - val_accuracy: 0.9760\n",
      "Epoch 7/10\n",
      "18/18 [==============================] - 49s 3s/step - loss: 0.0267 - accuracy: 0.9932 - val_loss: 0.2736 - val_accuracy: 0.9702\n",
      "Epoch 8/10\n",
      "18/18 [==============================] - 50s 3s/step - loss: 0.0168 - accuracy: 0.9965 - val_loss: 0.2574 - val_accuracy: 0.9716\n",
      "Epoch 9/10\n",
      "18/18 [==============================] - 49s 3s/step - loss: 0.0119 - accuracy: 0.9976 - val_loss: 0.2519 - val_accuracy: 0.9764\n",
      "Epoch 10/10\n",
      "18/18 [==============================] - 51s 3s/step - loss: 0.0104 - accuracy: 0.9981 - val_loss: 0.2918 - val_accuracy: 0.9640\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cf71c82550>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(x_train,steps_per_epoch=len(x_train),epochs=10,validation_data=x_test,validation_steps=len(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ad001b-c47a-4d0b-9cdb-d085afd83383",
   "metadata": {},
   "source": [
    "Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "952eca53-e5aa-4ad5-a868-5fd34080eafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('HandSign.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9707cca5-f4ed-4d07-b7b5-789275c2515b",
   "metadata": {},
   "source": [
    "Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6419505e-2ef1-4196-b1d0-3777feef99b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "da596de4-5e51-468e-a62d-64f257d61774",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=load_model('HandSign.h5')\n",
    "img=image.load_img(r'C:\\Users\\LEGION\\Desktop\\Project Externship\\Dataset\\test_set\\B\\2.png',\n",
    "                   target_size=(64,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5d4f0e95-100d-46cf-ac69-8f115d2e55c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEAAAABACAIAAAAlC+aJAAAB80lEQVR4nO2au43CQBCGxxc5RJAg0YBrcAAJPUAHdieIChyQOTESMQUQUYLpwHTgBGkJLBDiONiZndnH4S828/D8/y72GqCnxw/KslRKjUYj14WQUDdWq5XrWvBkWaYeWC6X8/ncdVEY8jxXrxiPxxayR+YhlFJ/Ro8Y4r/nRzqBNPQGiqLopPLmmsvlQo4vS5IkL3X/G+lKiBrVr0zaBhQJebVbUW4PShg+TgBF0zSdGfb7vUR8dANxHKOuv29nw+EQm0sH9HzjOG7blphMQE7oiIYrI3sPX7wTe8KXNUC27500TQ0jPIGzVNu22GX0OV/oJq6qijdg8B6wLSHgVpHtCWy3W96AuAbMbz87wXugb8A1wTeAW9FY3jKEvYwCwHq9tp8U4OHp1hDeqhxMIMsyxmgIOXLdvOA9sNlsGKM5mACwDkF3AnVdc6XkJfiNTBeWBbQjz3PGwnS16KcB4B9IyEEDRVHYT8rpAd7jVwfPxOfz2XJSAIC6rrkmwFuY7Z3Y5Zs5C8fuBHAeMBzCdDo1+TkDh8OBLP3j8ShRktUjJgkRopfR3W5Hy+SRhQj6WSwWQsVQNrIoirBPVZPJhJBIEP2vVTpc13vj/j/Mn+rFP7cBYfv2zwOfmM1m0ilwdIc0+gY4nU6i9fQe+MRgMBCNfwUUD+BDV2yOrgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=64x64 at 0x2CF71D15A60>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9e33e578-b1ed-4794-b51e-bc5ddb0d4ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=image.img_to_array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "49b7dec7-f980-4909-b3ad-df911571600c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "32925a8a-decf-45f1-bd84-6485ac49debf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ddd11098-8e27-4882-9288-173b37a21692",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.expand_dims(x,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fbbea74e-6070-43e5-be41-e6534522001a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]]]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f5839e05-0268-4b2a-b054-7c0d5e338cd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b849024e-f2ad-462b-a5c2-5f0f4359a5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=np.argmax(model.predict(x),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c9f80483-1fb4-4876-ae85-b64352991721",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "87b8634f-5b84-40e0-a8b6-5b2b5b3d451d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B\n"
     ]
    }
   ],
   "source": [
    "index=['A','B','C','D','E','F','G','H','I']\n",
    "print(index[pred[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d9a64f-2b56-4c71-b0ff-92fa057a714a",
   "metadata": {},
   "source": [
    "Open CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "107b6129-1bae-42eb-a583-877b2ddf3322",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "907cde54-9a60-4f9d-8a6a-17567fba1774",
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv2.imread(r'C:\\Users\\LEGION\\Desktop\\Project Externship\\Dataset\\test_set\\B\\2.png',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "837addfe-ab75-4201-9d9b-320648f5d903",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]]], dtype=uint8)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "04f82cd9-e8b6-41c2-b0d6-f6e144ae4fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "img1=cv2.imread(r'C:\\Users\\LEGION\\Desktop\\Project Externship\\Dataset\\test_set\\B\\2.png',0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cfcc6e26-4837-4634-9741-7f9966e20a70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "98198ad3-a83b-4371-8c48-6828eb5ebc71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b016cfae-e0d4-45c6-b72d-7f7d27ad99c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv2.imread(r'C:\\Users\\LEGION\\Desktop\\Project Externship\\Dataset\\test_set\\B\\2.png',1)\n",
    "cv2.imshow('image',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80dec3d1-afd2-4112-b42f-254baad0414c",
   "metadata": {},
   "source": [
    "CNN Video Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e54e922c-f4f6-4916-87cf-e3e2568dede4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "model=load_model('HandSign.h5')\n",
    "video=cv2.VideoCapture(0)\n",
    "index=['A','B','C','D','E','F','G','H','I']\n",
    "while 1:\n",
    "    succes,frame=video.read()\n",
    "    cv2.imwrite('image.jpg',frame)\n",
    "    img=image.load_img('image.jpg',target_size=(64,64))\n",
    "    x=image.img_to_array(img)\n",
    "    x=np.expand_dims(x,axis=0)\n",
    "    pred=np.argmax(model.predict(x),axis=1)\n",
    "    y=pred[0]\n",
    "    cv2.putText(frame,'The Predicted Alphabet is: '+str(index[y]),(100,100),cv2.FONT_HERSHEY_SIMPLEX,1,(0,0,0),4)\n",
    "    cv2.imshow('image',frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "video.release()\n",
    "cv2.destroyAllWindows()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81012e1-4079-4b09-9107-691330c5d5d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
